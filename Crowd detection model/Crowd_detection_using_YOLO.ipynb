{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaqCSeR2dMUeG0+NBA++7Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suyashmarathe512/suyash/blob/main/Crowd%20detection%20model/Crowd_detection_using_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python numpy pandas scikit-learn\n",
        "\n",
        "# Import necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "from sklearn.cluster import DBSCAN\n",
        "import os\n",
        "\n",
        "# Download the YOLOv3 weights and configuration files.\n",
        "# These files are needed for the cv2.dnn.readNet() function to work.\n",
        "# This downloads the file to the same directory as the notebook.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruiQ2FlxCG7p",
        "outputId": "6f604457-c0a1-48b8-916f-6fde232ff7e8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "if not os.path.exists('yolov3.weights'):\n",
        "    wget.download(\"https://pjreddie.com/media/files/yolov3.weights\")\n",
        "if not os.path.exists('yolov3.cfg'):\n",
        "    wget.download(\"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZCKsb4fDk9b",
        "outputId": "6e9aa1c4-053c-4697-b1a9-299ba8e424c9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.11/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27CBn0jbCmxX",
        "outputId": "e2be444f-2c9f-44e4-f5ae-b1e8decd99de"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'yolov3.cfg', '.ipynb_checkpoints', 'yolov3.weights', 'dataset_video.mp4', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "layer_names = net.getLayerNames()\n",
        "unconnected_layers = net.getUnconnectedOutLayers()\n",
        "\n",
        "# Check if the output is a NumPy array or a list of lists\n",
        "if isinstance(unconnected_layers, np.ndarray):\n",
        "    # If it's a NumPy array (newer OpenCV), process accordingly\n",
        "    output_layers = [layer_names[i - 1] for i in unconnected_layers.flatten()]\n",
        "else:\n",
        "    # If it's a list of lists (older OpenCV), process as before\n",
        "    output_layers = [layer_names[i[0] - 1] for i in unconnected_layers]"
      ],
      "metadata": {
        "id": "VUfMJjxMCgdQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_persons(frame):\n",
        "    height, width = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outputs = net.forward(output_layers)\n",
        "\n",
        "    boxes, confidences = [], []\n",
        "    for output in outputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if class_id == 0 and confidence > 0.5:  # 'person' class\n",
        "                box = detection[0:4] * np.array([width, height, width, height])\n",
        "                (x, y, w, h) = box.astype(\"int\")\n",
        "                boxes.append([x, y, int(w), int(h)])\n",
        "                confidences.append(float(confidence))\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    if indices is not None and indices.size > 0:\n",
        "        # Flatten the indices array to handle both 1D and 2D array cases\n",
        "        indices = indices.flatten()\n",
        "        return [boxes[i] for i in indices]  # Access boxes directly with the index\n",
        "    else:\n",
        "        return []"
      ],
      "metadata": {
        "id": "es18vdpJBpYx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_crowd(persons, eps=100, min_samples=3):\n",
        "    if len(persons) < min_samples:\n",
        "        return []\n",
        "    # Get center points of bounding boxes\n",
        "    centers = np.array([(x + w/2, y + h/2) for (x, y, w, h) in persons])\n",
        "    # Use DBSCAN to cluster nearby persons\n",
        "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(centers)\n",
        "    labels = clustering.labels_\n",
        "    # Count unique clusters (ignore noise label -1)\n",
        "    clusters = {}\n",
        "    for label, (x, y, w, h) in zip(labels, persons):\n",
        "        if label != -1:\n",
        "            clusters.setdefault(label, []).append((x, y, w, h))\n",
        "    return [group for group in clusters.values() if len(group) >= 3]\n"
      ],
      "metadata": {
        "id": "3JkbW_HDBuZz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4wLPj3BaBaHT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def process_video(video_path, output_csv=\"crowd_log.csv\"):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    crowd_buffer = deque(maxlen=10)  # Track last 10 frames\n",
        "    log_data = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_count += 1\n",
        "\n",
        "        persons = detect_persons(frame)\n",
        "        crowd_groups = is_crowd(persons)\n",
        "\n",
        "        # Check if any crowd exists in this frame\n",
        "        crowd_detected = len(crowd_groups) > 0\n",
        "        crowd_buffer.append(crowd_detected)\n",
        "\n",
        "        # Log if 10 consecutive frames have crowds\n",
        "        if len(crowd_buffer) == 10 and all(crowd_buffer):\n",
        "            # Get the largest crowd group size\n",
        "            max_size = max(len(group) for group in crowd_groups) if crowd_groups else 0\n",
        "            log_data.append({\"Frame Number\": frame_count, \"Person Count in Crowd\": max_size})\n",
        "            crowd_buffer.clear()  # Reset buffer after logging\n",
        "\n",
        "    # Save to CSV\n",
        "    df = pd.DataFrame(log_data)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    cap.release()\n",
        "\n",
        "#Create a dummy video if the user does not have one.\n",
        "if not os.path.exists('dataset_video.mp4'):\n",
        "    !ffmpeg -f lavfi -i color=c=blue:s=640x480:d=10 -pix_fmt yuv420p dataset_video.mp4\n",
        "# Example usage\n",
        "process_video(\"dataset_video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlOsyiS3CryM"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}